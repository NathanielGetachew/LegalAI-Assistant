{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "86c59c80",
      "metadata": {
        "id": "86c59c80"
      },
      "source": [
        "# üß† Legal Classification with Self-Consistency and Chain-of-Thought Reasoning\n",
        "\n",
        "## üìò Introduction\n",
        "\n",
        "This project explores the application of advanced prompt engineering techniques‚Äî**Chain-of-Thought (CoT) Reasoning** and **Self-Consistency**‚Äîto classify legal scenarios into predefined violation types. The aim is to simulate how an AI Legal Assistant can infer the correct legal classification from textual complaints or case summaries, improving both transparency and reliability in decision-making.\n",
        "\n",
        "## üõ†Ô∏è Methodology\n",
        "\n",
        "### üß© Chain-of-Thought (CoT) Prompting\n",
        "\n",
        "**Chain-of-Thought reasoning** enhances model outputs by explicitly guiding the language model through intermediate reasoning steps. Instead of directly asking for a classification, the prompt requests the model to:\n",
        "\n",
        "- Analyze the text\n",
        "- Identify key legal issues\n",
        "- Justify the classification\n",
        "- Predict the final label\n",
        "\n",
        "This encourages more explainable and accurate decisions.\n",
        "\n",
        "### üîÅ Self-Consistency\n",
        "\n",
        "The **Self-Consistency** method involves generating multiple completions (e.g. 5) for the same prompt and selecting the most consistent output using majority voting. This helps mitigate randomness and hallucination from the model. It works as follows:\n",
        "\n",
        "1. Generate multiple responses from the model for each prompt.\n",
        "2. Collect the predicted labels.\n",
        "3. Choose the most frequent prediction as the final answer.\n",
        "\n",
        "Combining CoT and Self-Consistency results in both reasoned and reliable classifications.\n",
        "\n",
        "## üß™ Experimental Setup\n",
        "\n",
        "- **Dataset**: [LegalLens NLI Subset] used to manually prepare 5 legal classification cases.\n",
        "- **Model**: Gemini 1.5 Flash (via `generativelanguage` API)\n",
        "- **Classes**:\n",
        "  - breach of employment contract  \n",
        "  - defamation (libel)  \n",
        "  - patent infringement  \n",
        "  - premises liability due to negligence  \n",
        "  - fraudulent misrepresentation  \n",
        "\n",
        "- **Evaluation Metrics**:\n",
        "  - Accuracy\n",
        "  - Precision, Recall, F1-score (per class)\n",
        "\n",
        "## üìä Results\n",
        "\n",
        "### Final Predictions (CoT + Self-Consistency)\n",
        "\n",
        "| Case ID | Expected                             | Predicted                            | Match |\n",
        "|---------|--------------------------------------|--------------------------------------|-------|\n",
        "| 001     | breach of employment contract        | breach of employment contract        | ‚úÖ    |\n",
        "| 002     | defamation (libel)                   | defamation (libel)                   | ‚úÖ    |\n",
        "| 003     | patent infringement                  | patent infringement                  | ‚úÖ    |\n",
        "| 004     | premises liability due to negligence | premises liability due to negligence | ‚úÖ    |\n",
        "| 005     | fraudulent misrepresentation         | fraudulent misrepresentation         | ‚úÖ    |\n",
        "\n",
        "### üìà Classification Report\n",
        "\n",
        "\n",
        "## ‚úÖ Conclusion\n",
        "\n",
        "This experiment demonstrates that combining **Chain-of-Thought prompting** with **Self-Consistency** significantly improves the performance of LLMs on nuanced legal classification tasks. The model achieved **100% accuracy** on the test cases when both techniques were used together.\n",
        "\n",
        "These findings suggest that prompt engineering strategies can be as effective as fine-tuning for certain classification tasks, especially in settings where transparency and justification are critical (e.g., legal and healthcare domains).\n",
        "\n",
        "## üìå References\n",
        "\n",
        "- Google AI Gemini API Documentation: [https://ai.google.dev](https://ai.google.dev)\n",
        "- Wei et al., *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*, arXiv:2201.11903\n",
        "- Wang et al., *Self-Consistency Improves Chain of Thought Reasoning in Language Models*, arXiv:2203.11171\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}